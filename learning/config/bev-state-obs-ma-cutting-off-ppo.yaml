bev-state-obs-ma-cutting-off-ppo:
  local_dir: ~/tmp
  env: MultiAgentStateObs
  run: PPO
  num_samples: 1
  checkpoint_freq: 10
  checkpoint_at_end: true
  stop:
    episode_reward_mean: 99999
    timesteps_total: 1e7 # 10M
  ray_resources:
    num_cpus: 20
    num_gpus: 1
  config:
    num_workers: 16
    num_gpus: 0.2
    num_gpus_per_worker: 0.05
    framework: torch
    # environment
    env_config:
      to_bev_map: true
      task: CuttingOff
      trace_paths: [~/data/20190205-102931_blue_prius_devens_rightside]
      mesh_dir: ~/data/old_vista_mesh_lib_calib/
      init_agent_range: [6, 12]
      collision_overlap_threshold: 0.05
      respawn_distance: 10
      wrappers: [StackObservation, ContinuousKinematic, DistanceReward, RandomPermuteAgent]
      wrappers_config:
        StackObservation:
          frame_stack: 5
        ContinuousKinematic:
          d_curvature_bound: [-5., 5.]
          d_velocity_bound: [-15., 15.]
        DistanceReward:
          reward_coef: 0.001
          scale_with_dist: true
          cutoff_dist: null
        RandomPermuteAgent:
          permute_prob: 0.5
    observation_filter: NoFilter
    callbacks: BasicCallbacks
    # policies
    multiagent:
      policies: [default_policy_0, default_policy_1]
      policies_to_train: [default_policy_0]
      policy_mapping_fn: one_to_one
      callbacks_config:
        n_recent_ckpt: 10
        ckpt_freq: 2
        main_policy_id: default_policy_0
        ckpt_policy_id: default_policy_1
    # MDP-related
    gamma: 0.99
    rollout_fragment_length: 200
    # sgd-related
    lr: 0.0002
    lr_schedule: null
    num_sgd_iter: 8
    train_batch_size: 32000
    sgd_minibatch_size: 512 # larger batch size is better
    # value function
    vf_loss_coeff: 1.0
    vf_clip_param: 1000.0
    # PPO-specific
    entropy_coeff: 0.01
    entropy_coeff_schedule: null
    lambda: 0.95
    kl_coeff: 0.2
    kl_target: 0.01
    clip_param: 0.3
    # model
    model:
      vf_share_layers: true
      custom_model: ConvNet
      conv_filters: [
        [15, 24, 5, 2, 2],
        [24, 36, 5, 2, 2], 
        [36, 48, 3, 2, 1], 
        [48, 64, 3, 1, 1], 
        [64, 64, 3, 1, 1]
      ]
      conv_activation: relu
      custom_action_dist: TorchBeta # prevent inf logprob
      custom_model_config:
        with_bn: false #true
        vec_obs_dim: 2
        policy_hiddens: [66, 32, 4]
        policy_activation: relu
        value_fcnet_hiddens: [66, 32, 1]
        value_fcnet_activation: relu
        custom_action_dist_config:
          low: [-5., -15.]
          high: [5., 15.]